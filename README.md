# _Project for AMLS_assignment20_21_

This project completes the assignment released by AMLS in 2020-21


## _Description_

In the project, different ML algorithms were manipulated to solve four facial classification problems.
One of them was chosen  as the final solution.


The overall structure is:

[1] Four models folder: A1, A2, B1, B2 (contains the code used for solving task(model_~.py), codes for other possible models (for fun), 
codes for feature extraction(dlib based), .dat file(used by predictor in dlib))

[2] One dataset folder: should be given initial set, added test set for cartoon image; initial set, added test set for celeba image

[3] One main code: here all pre-trained models were loaded and give a final presentation to model performance

[4] Others(can be ignored): git, PyCharm project setting files. 

Note: .dat file along with complete dataset was uploaded to OneDrive. The link can be viewed in report

## _Structure_

### A1

#### model_a1.py
This code contains the final model used for solving task A1. The detailed description, implementation and result
can be found in report. The code in this file has the most strict and complete form and can be used for marking.

#### model_a1.pkl
This file contains pre-trained model and will be used in main.py to give training and test accuracy.

#### knn_a1.py/rand_forest_a1.py/svm_a1.py/mlp_a1.py/cnn_a1.py
These codes contain different model's training and testing pipline. The codes here are not as strict or complete as model
_a1.py. They're for playing. Still, they can give all model training procedure including feature extraction, training, 
validation, testing...The plots generated by these codes were attached to the report appendix.

#### dlib_feature_extract_a1.py/dlib_feature_extract_a1_test.py
These two files were built based on the one provided in lab. They realize automatic image loading, dlib 68 key points 
extraction and label extraction. They can also return the coordinates of these points and marked images. The only difference
between them is loaded data. One is for loading images and labels provided initially for training. One is for loading images
and labels in additional test set.

#### shape_predictor_68_face_landmarks.dat
This is the pre-trained model for 68 key points extraction.
### A2/B1/B2
**Note: the directory A2, B1, B2 has the same structure in A1 and therefore will not be repeated.**
### Datasets
This directory will contain the dataset used  by models. Just put following directories in this directory:

[1]cartoon_set;

[2]cartoon_set_test;

[3]celeba;

[4]celeba_test

The codes will extract images and labels information and do other manipulations.

### venv(ignore)
This directory contains some PyCharm project information such license and so on.

### .gitignore(ignore)
This is a git project file telling Git which files will not be added into version control.

### main.py(!)
This code will generate training and test set and then loaded the pre-trained models for giving training and testing accuracies. 
If want to re-train the model or check the pipline, please find the relevant model_~.py file in A1, A2, B1, B2 directory.


